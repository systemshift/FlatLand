# Mesa Code Generator via LLM

This project aims to take a natural language description of a simulation, use an LLM (e.g., OpenAI's GPT models) to generate Python code for the [Mesa agent-based modeling framework](https://mesa.readthedocs.io/), and then execute that simulation.

## Project Structure

- `app.py`: Main Flask application. Handles API requests and orchestrates the generation and execution of Mesa models.
- `openai_interface.py`: Module for interacting with the OpenAI API to translate natural language prompts into Mesa code.
- `mesa_runner.py`: Module responsible for executing the LLM-generated Mesa code. **WARNING: Current implementation uses `exec()` and is not secure for production.**
- `requirements.txt`: Python dependencies.
- `.env.example`: Template for environment variables (e.g., API keys). Rename to `.env` and populate.
- `templates/`: Directory for HTML templates (for future web UI).
- `static/`: Directory for static assets (CSS, JavaScript for future web UI).
- `generated_models/`: (Optional) Can be used to store or manage generated Mesa code files if needed.

## Setup

1.  **Create and activate a virtual environment:**
    ```bash
    python -m venv venv
    source venv/bin/activate  # On Windows: venv\Scripts\activate
    ```

2.  **Install dependencies:**
    ```bash
    pip install -r requirements.txt
    ```

3.  **Set up environment variables:**
    - Rename `.env.example` to `.env`.
    - Add your OpenAI API key to the `.env` file:
      `OPENAI_API_KEY="YOUR_OPENAI_API_KEY_HERE"`

## Running the Application (Backend Only - Initial Phase)

```bash
python app.py
```
The Flask development server will start (likely on `http://127.0.0.1:5001`).

## API Endpoint

### `/generate_mesa`

-   **Method:** `POST`
-   **Body (JSON):**
    ```json
    {
        "prompt": "Your natural language description of the Mesa simulation."
    }
    ```
-   **Response (JSON):**
    -   Success: Information about the received prompt and (eventually) the simulation result.
    -   Error: Error message if the prompt is missing or an issue occurs.

## Security Warning

The `mesa_runner.py` currently uses `exec()` to run code generated by an LLM. This is **highly insecure** and should **not** be used in a production environment or any environment where security is a concern without implementing proper sandboxing (e.g., Docker containers, `RestrictedPython`). This MVP implementation prioritizes demonstrating the core workflow.

## Future Work

-   Implement actual OpenAI API calls in `openai_interface.py`.
-   Develop a secure sandboxed environment for `mesa_runner.py`.
-   Build out the web UI in `templates/` and `static/` for user input and simulation visualization.
-   Refine LLM prompt engineering for more robust and accurate Mesa code generation.
-   Implement mechanisms for displaying Mesa simulation outputs/visualizations on the web page.
